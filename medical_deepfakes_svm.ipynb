{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medical_deepfakes_svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunjaec/MScA_Machine_Learning_Project/blob/main/medical_deepfakes_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os \n",
        "import seaborn as sns\n",
        "try:\n",
        "  import pydicom\n",
        "except:\n",
        "  ! pip install pydicom\n",
        "  import pydicom\n",
        "import scipy.ndimage"
      ],
      "metadata": {
        "id": "GjCTID7ea9fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d04b23-41bb-4657-fa04-31f552bd48be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhpK6XXdayjh",
        "outputId": "bcc9c3c8-17e4-46da-bb66-6424494740c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dicom(path2scan_dir):\n",
        "    dicom_folder = path2scan_dir\n",
        "    dcms = os.listdir(dicom_folder)\n",
        "    first_slice_data = pydicom.read_file(os.path.join(path2scan_dir,dcms[0]))\n",
        "    first_slice = first_slice_data.pixel_array\n",
        "    orientation = np.transpose(first_slice_data.ImageOrientationPatient) #zyx format\n",
        "    spacing_xy = np.array(first_slice_data.PixelSpacing, dtype=float)\n",
        "    spacing_z = np.float(first_slice_data.SliceThickness)\n",
        "    spacing = np.array([spacing_z, spacing_xy[1], spacing_xy[0]]) #zyx format\n",
        "\n",
        "    scan = np.zeros((len(dcms),first_slice.shape[0],first_slice.shape[1]))\n",
        "    raw_slices=[]\n",
        "    indexes = []\n",
        "    for dcm in dcms:\n",
        "        slice_data = pydicom.read_file(os.path.join(dicom_folder,dcm))\n",
        "        slice_data.filename = dcm\n",
        "        raw_slices.append(slice_data)\n",
        "        indexes.append(float(slice_data.ImagePositionPatient[2]))\n",
        "    indexes = np.array(indexes,dtype=float)\n",
        "\n",
        "    raw_slices = [x for _, x in sorted(zip(indexes, raw_slices))]\n",
        "    origin = np.array(raw_slices[0][0x00200032].value) #origin is assumed to be the image location of the first slice\n",
        "    if origin is None:\n",
        "        origin = np.zeros(3)\n",
        "    else:\n",
        "        origin = np.array([origin[2],origin[1],origin[0]]) #change from x,y,z to z,y,x\n",
        "\n",
        "    for i, slice in enumerate(raw_slices):\n",
        "        scan[i, :, :] = slice.pixel_array\n",
        "    return scan, spacing, orientation, origin, raw_slices"
      ],
      "metadata": {
        "id": "l4MZgRxGbIz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls 'drive/My Drive/data_ml'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa5LwJ7jGHi9",
        "outputId": "ab02a1cb-4f9d-40bd-9635-93959722f58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Experiment 2 - Open'\n",
            " labels_exp2.csv\n",
            "'Response EXP2 - Reviewer 1_instances.csv'\n",
            "'Response EXP2 - Reviewer 1_patients.csv'\n",
            "'Response EXP2 - Reviewer 2_instances.csv'\n",
            "'Response EXP2 - Reviewer 2_patients.csv'\n",
            "'Response EXP2 - Reviewer 3_instances.csv'\n",
            "'Response EXP2 - Reviewer 3_patients.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('drive/My Drive/data_ml/Experiment 2 - Open')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdLicwSeCsmm",
        "outputId": "e674068b-68ff-4523-d9ff-0671f8edb1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2220',\n",
              " '1563',\n",
              " '2575',\n",
              " '1876',\n",
              " '2031',\n",
              " '3341',\n",
              " '6031',\n",
              " '7507',\n",
              " '2592',\n",
              " '1251',\n",
              " '4709',\n",
              " '2960',\n",
              " '4635',\n",
              " '1796',\n",
              " '2366',\n",
              " '2590',\n",
              " '2199',\n",
              " '2495',\n",
              " '2703',\n",
              " '1610']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "scan_uuids = os.listdir('drive/My Drive/data_ml/Experiment 2 - Open')\n",
        "\n",
        "scan = None\n",
        "spacing = None\n",
        "orientation = None\n",
        "origin = None\n",
        "raw_slices = []\n",
        "for id in tqdm(scan_uuids):\n",
        "  sc, sp, ori, org, rs = load_dicom('/content/drive/My Drive/data_ml/Experiment 2 - Open/'+id)\n",
        "  if scan is None:\n",
        "    scan = sc\n",
        "  else:\n",
        "    scan = np.concatenate((scan, sc))\n",
        "  if spacing is None:\n",
        "    spacing = sp\n",
        "  else:\n",
        "    spacing = np.concatenate((spacing, sp))\n",
        "  if orientation is None:\n",
        "    orientation = ori\n",
        "  else:\n",
        "    orientation = np.concatenate((orientation, ori))\n",
        "  if origin is None:\n",
        "    origin = org\n",
        "  else:\n",
        "    origin = np.concatenate((origin, org))\n",
        "  raw_slices += rs\n",
        "\n",
        "print('The CT scan has the dimensions of',scan.shape,'  (z,y,x)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trYPbA1ebJdk",
        "outputId": "6a6214c9-519e-425a-e43b-b428db56bd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            " 35%|███▌      | 7/20 [01:31<02:07,  9.79s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "for slice_indx in range(50,100,10):\n",
        "    plt.imshow(scan[slice_indx,:,:],cmap='bone',vmin=-1000,vmax=2000)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oKssG0mCbNCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/data_ml/labels_exp2.csv')\n",
        "locations = df.loc[df['uuid'].isin(scan_uuids)]\n",
        "locations"
      ],
      "metadata": {
        "id": "vGsmqYTwcGZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cutCube(X, center, shape, padd=0): #center is a 3d coord (zyx)\n",
        "    center = center.astype(int)\n",
        "    hlz = np.round(shape[0] / 2)\n",
        "    hly = np.round(shape[1] / 2)\n",
        "    hlx = np.round(shape[2] / 2)\n",
        "\n",
        "    #add padding if out of bounds\n",
        "    if ((center - np.array([hlz,hly,hlx])) < 0).any() or (\n",
        "        (center + np.array([hlz,hly,hlx]) + 1) > np.array(X.shape)).any():  # if cropping is out of bounds, add padding\n",
        "        try:\n",
        "          np.ones(np.array(X.shape) + shape * 2)\n",
        "        except:\n",
        "          return \"No\"\n",
        "        Xn = np.ones(np.array(X.shape) + shape * 2) * padd\n",
        "        Xn[shape[0]:(shape[0] + X.shape[0]), shape[1]:(shape[1] + X.shape[1]), shape[2]:(shape[2] + X.shape[2])] = X\n",
        "        centern = center + shape\n",
        "        cube = Xn[int(centern[0] - hlz):int(centern[0] - hlz + shape[0]),\n",
        "               int(centern[1] - hly):int(centern[1] - hly + shape[1]),\n",
        "               int(centern[2] - hlx):int(centern[2] - hlx + shape[2])]\n",
        "        return np.copy(cube)\n",
        "    else:\n",
        "        cube = X[int(center[0] - hlz):int(center[0] - hlz + shape[0]), int(center[1] - hly):int(center[1] - hly + shape[1]),\n",
        "               int(center[2] - hlx):int(center[2] - hlx + shape[2])]\n",
        "        return np.copy(cube)\n"
      ],
      "metadata": {
        "id": "WdsVYBl-cNHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_cubes = []\n",
        "for i in range(len(locations)):\n",
        "    location = locations.iloc[i]\n",
        "    coord = np.array([location['slice'],location['y'],location['x']])\n",
        "    cut_cubes.append(cutCube(scan,coord,(64,64,64)))\n",
        "\n",
        "#disply the slices of each cut cube:\n",
        "# for cube in cut_cubes:\n",
        "#     plt.figure(num=None, figsize=(10, 10), dpi=200)\n",
        "#     for i in range(64):\n",
        "#         plt.subplot(8,8,i+1)\n",
        "#         plt.axis('off')\n",
        "#         plt.tight_layout()\n",
        "#         try:\n",
        "#           plt.imshow(cube[i,:,:],cmap='bone')\n",
        "#         except:\n",
        "#           print(i)\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "zn4b5NTLcO8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dir = \"/content/drive/My Drive/Data/data_ml/Experiment 2 - Open/\"\n",
        "r=[]\n",
        "for root, dirs, files in os.walk(dir):\n",
        "  r.append(root)"
      ],
      "metadata": {
        "id": "G8KA-d-BlJ32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_df1 = pd.read_csv('/content/drive/My Drive/data_ml/Response EXP2 - Reviewer 1_instances.csv')\n",
        "label_df2 = pd.read_csv('/content/drive/My Drive/data_ml/Response EXP2 - Reviewer 2_instances.csv')\n",
        "label_df3 = pd.read_csv('/content/drive/My Drive/data_ml/Response EXP2 - Reviewer 3_instances.csv')\n",
        "\n",
        "preds = pd.concat([label_df1[['label','prediction','confidence']], label_df2[['label','prediction','confidence']], label_df3[['label','prediction','confidence']]], axis = 1)\n",
        "preds.columns = ['label1','prediction1','confidence1','label2','prediction2','confidence2','label3','prediction3','confidence3']\n",
        "\n",
        "def final_label(row):\n",
        "  row.label1 = row.labe1.replace(False, -1)\n",
        "  if row.label1 == row.label2 == row.label3:\n",
        "    return row.label1\n",
        "  else:\n",
        "    return np.sign((row.label1*row.confidence1 + row.label1*row.confidence2 + row.label1*row.confidence3) / 3)\n",
        "\n",
        "preds['label'] = preds.apply(lambda row: final_label(row), axis = 1)\n",
        "label_df = pd.concat([label_df1.drop('label', axis = 1), preds['label']], axis = 1)\n",
        "label_df.head()"
      ],
      "metadata": {
        "id": "64YDIvHmnG--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_true = label_df.loc[label_df['label']==True]\n",
        "df_false = label_df.loc[label_df['label']==False]\n",
        "len(label_df)"
      ],
      "metadata": {
        "id": "19HkTZtcwvQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_true.uuid[0]"
      ],
      "metadata": {
        "id": "gxJZ4ncHoZKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_true = df_true.reset_index()\n",
        "df_false = df_false.reset_index()"
      ],
      "metadata": {
        "id": "hpfKjEaH53Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def image_cut_processing(df):\n",
        "  cut_cubes = []\n",
        "  for i in tqdm(range(0,len(df))):\n",
        "    scan, spacing, orientation, origin, raw_slices = load_dicom('/content/drive/My Drive/data_ml/Experiment 2 - Open/'+str(df.uuid[i]))\n",
        "    uuid_row = df.loc[df['uuid'] == df.uuid[i]]\n",
        "    for j in range(len(uuid_row)):\n",
        "      location = uuid_row.iloc[j]\n",
        "      coord = np.array([location['slice'],location['y'],location['x']])\n",
        "      if (cutCube(scan,coord,(64,64,64))) != \"No\":\n",
        "        cut_cubes.append(cutCube(scan,coord,(64,64,64)))\n",
        "  return cut_cubes\n",
        "  "
      ],
      "metadata": {
        "id": "kcEebwwlnxcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_cut_images = image_cut_processing(df_true)"
      ],
      "metadata": {
        "id": "PYK_F6HcoLnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "false_cut_images = image_cut_processing(df_false)"
      ],
      "metadata": {
        "id": "1Ot2CgXep7ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [True for i in range(len(true_cut_images))]\n",
        "list2 = [False for i in range(len(false_cut_images))]\n",
        "y = list1+list2\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "upSzCBDd-lXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(y)"
      ],
      "metadata": {
        "id": "DE4kdHPPTbrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = true_cut_images + false_cut_images"
      ],
      "metadata": {
        "id": "XMuWG8ZW8Esv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "id": "0pgd61PXJC--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y['label'] = (y[True] == 1).astype(int)"
      ],
      "metadata": {
        "id": "hVPCewBkQd15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y['label'], test_size=.2)"
      ],
      "metadata": {
        "id": "gMSZ1VIb96ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "lhbUNcU8A1Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train), len(y_test)"
      ],
      "metadata": {
        "id": "FT8GLjFVSpm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.label.to_numpy()"
      ],
      "metadata": {
        "id": "K99MaU5a2Bdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[8].shape, y_train[8].shape"
      ],
      "metadata": {
        "id": "eVrb7pygHXO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "CTuMcmJZQKbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nsamples, nx, ny, nz = X_train.shape\n",
        "X_train_flattened = X_train.reshape((nsamples,nx*ny*nz))\n",
        "X_test_flattened = X_test.reshape((X_test.shape[0],nx*ny*nz))"
      ],
      "metadata": {
        "id": "vQAhVjt7Rokq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_flattened.shape"
      ],
      "metadata": {
        "id": "iLxivA0vRwnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(X_train_flattened, y_train)"
      ],
      "metadata": {
        "id": "Oqc99UIvM6TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "preds = svc.predict(X_test_flattened)\n",
        "\n",
        "print(confusion_matrix(y_test, preds))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, preds))"
      ],
      "metadata": {
        "id": "bECo9K6sR0f2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}